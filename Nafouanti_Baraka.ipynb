{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1824932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] =(9, 9)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "import warnings\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11faceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('eng.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b3b5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n",
    "df.info()\n",
    "df.isnull().any()\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(10,'Score'))  #print 10 best features\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "mask = np.triu(np.ones_like(df.corr()))\n",
    "\n",
    "f,ax = plt.subplots(figsize=(16,8))\n",
    "               \n",
    "corr=df.corr()\n",
    "\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True, center = 'dark')               \n",
    "\n",
    "sns.heatmap(df.corr(), annot=True, fmt ='.1f',mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "ax.set_title('Correlation Matrix')\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "df.plot(figsize=(16,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e0d06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"F\", axis=1)\n",
    "y = df[\"F\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f759f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2387fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e7ef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab9e8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6b77b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "HRFLM_estimators = []\n",
    "\n",
    "# Defining 1 Logistic Regression Model\n",
    "model11 = LogisticRegression(random_state = 2030,C=10, max_iter=5000)\n",
    "HRFLM_estimators.append(('logistic1', model11))\n",
    "\n",
    "\n",
    "# Defining 3 Random Forest Models\n",
    "model21 = RandomForestClassifier(random_state = 2030)\n",
    "HRFLM_estimators.append(('RF1', model21))\n",
    "\n",
    "model22 = RandomForestClassifier(random_state = 2030) \n",
    "HRFLM_estimators.append(('RF2', model22))\n",
    "\n",
    "model23 = RandomForestClassifier(random_state = 2030)\n",
    "HRFLM_estimators.append(('RF3', model23))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d143e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the HRFLM ensemble model\n",
    "HRFLM_ensemble = VotingClassifier(HRFLM_estimators,voting='soft',)\n",
    "results = {}\n",
    "#Training the model \n",
    "start = time()\n",
    "HRFLM_ensemble.fit(X_train,y_train)\n",
    "end = time()\n",
    "results['training_time'] = end - start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c43d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "HRFLM_Prediction = HRFLM_ensemble.predict(X_test)\n",
    "end = time()\n",
    "results['testing_time'] = end - start\n",
    "\n",
    "print(\"MODELLING TIMES(ms) OF HRFLM ARE:\")\n",
    "print(\"********************************************\")\n",
    "print(\"Training time: \"+\"{:.2f}\".format(results['training_time']))\n",
    "print(\"Testing time: \"+\"{:.2f}\".format(results['testing_time']))\n",
    "print(\"********************************************\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce855578",
   "metadata": {},
   "outputs": [],
   "source": [
    "HRFLM_Accuracy = accuracy_score(y_test, HRFLM_Prediction)\n",
    "print(\"The accuracy score for HRFLM in percentage is: \"+\"{:.2f}\".format(HRFLM_Accuracy*100))\n",
    "\n",
    "## Precision\n",
    "HRFLM_Precision = precision_score(y_test, HRFLM_Prediction)\n",
    "print(\"The precision score for HRFLM is: \"+\"{:.2f}\".format(HRFLM_Precision))\n",
    "\n",
    "## Recall \n",
    "HRFLM_Recall = recall_score(y_test, HRFLM_Prediction)\n",
    "print(\"The recall score for HRFLM is as follows: \"+\"{:.2f}\".format(HRFLM_Recall))\n",
    "\n",
    "## F1 Score\n",
    "HRFLM_F1Score = f1_score(y_test, HRFLM_Prediction)\n",
    "print(\"The F1 Score for HRFLM is: \"+\"{:.2f}\".format(HRFLM_F1Score))\n",
    "\n",
    "## Confusion Matrix \n",
    "HRFLM_Confusion_Matrix=confusion_matrix(y_test,HRFLM_Prediction)\n",
    "print(\"Confusion_Matrix: \\n\\n\",HRFLM_Confusion_Matrix, \"\\n\" )\n",
    "\n",
    "## Classification Report\n",
    "target_names =['class 0', 'class 1']\n",
    "print(classification_report(y_test,HRFLM_Prediction,zero_division=1,target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735c4f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity=HRFLM_Confusion_Matrix[0][0]/(HRFLM_Confusion_Matrix[0][0]+HRFLM_Confusion_Matrix[0][1])\n",
    "print(\"Specificity is: {}\".format(sensitivity))\n",
    "specificity=HRFLM_Confusion_Matrix[1][1]/(HRFLM_Confusion_Matrix[1][0]+HRFLM_Confusion_Matrix[1][1])\n",
    "print(\"Sensitivity is: {}\".format(specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d75e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "y_pred_proba =HRFLM_ensemble .predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"HRFLM, auc=\"+str(auc))\n",
    "plt.legend(loc=8)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0,1],[0,1],'-', color='blue') #diagonal line\n",
    "plt.title('HRFLM ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a093c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are trying to finding best option for parameters. There are values for trying.\n",
    "param_grid = {\n",
    "    \"max_depth\": [2,3,4,5,10],\n",
    "    \"learning_rate\": [0.1, 0.01, 0.05, 1.0, 3],\n",
    "    \"gamma\": [0,0.25,1.0, 1.5, 2],\n",
    "    \"reg_lambda\": [0, 2.0, 1.0, 10.0,100],\n",
    "    \"scale_pos_weight\": [1,3,5,7,10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a1eea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rom sklearn.model_selection import GridSearchCV\n",
    "params={\n",
    "     \"max_depth\": [\"None\",10, 30, 50, 75, 100],\n",
    "    \"max_features\": [\"auto\",0.3, 0.6],\n",
    "    \"min_samples_leaf\": [1,3,5,7],\n",
    "    \"min_samples_split\": [2, 4, 8, 12],\n",
    "    \"n_estimators\": [30, 50, 100, 200],\n",
    "    \"random_state\" : [42]    \n",
    "}\n",
    "HRFLM_ensemble = VotingClassifier(HRFLM_estimators,voting='soft')\n",
    "HRFLM_ensemble_grid = GridSearchCV(HRFLM_ensemble, params, scoring='accuracy', cv=7, n_jobs=-1)\n",
    "HRFLM_ensemble_grid.fit(X_train, y_train)\n",
    "## Output\n",
    "print(\"Best parameters:  {}:\".format(HRFLM_ensemble_grid.best_params_))\n",
    "print(\"Best score: {}\".format(HRFLM_ensemble_grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6be919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821377ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2901296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c3be60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc747b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c76b997",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee0c3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity=cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "print(\"Specificity is: {}\".format(sensitivity))\n",
    "specificity=cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "print(\"Sensitivity is: {}\".format(specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a5f52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b0a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cr)\n",
    "from sklearn import metrics\n",
    "y_pred_proba = clf.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"RF, auc=\"+str(auc))\n",
    "plt.legend(loc=8)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0,1],[0,1],'-', color='red') #diagonal line\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7afe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params={\n",
    "     \"max_depth\": [\"None\",10, 30, 50, 75, 100],\n",
    "    \"max_features\": [\"auto\",0.3, 0.6],\n",
    "    \"min_samples_leaf\": [1,3,5,7],\n",
    "    \"min_samples_split\": [2, 4, 8, 12],\n",
    "    \"n_estimators\": [30, 50, 100, 200],\n",
    "    \"random_state\" : [42]    \n",
    "}\n",
    "clf = RandomForestClassifier()\n",
    "clf_grid = GridSearchCV(clf, params, scoring='accuracy', cv=7, n_jobs=-1)\n",
    "clf_grid.fit(X_train, y_train)\n",
    "## Output\n",
    "print(\"Best parameters:  {}:\".format(clf_grid.best_params_))\n",
    "print(\"Best score: {}\".format(clf_grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2043e8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('F').count()\n",
    "ckd = 250\n",
    "notckd = 150\n",
    "\n",
    "chart_labels = ['1', '0']\n",
    "data = [ckd, notckd]\n",
    "\n",
    "plt.pie(data,autopct='%1.0f%%',pctdistance=0.5, labeldistance=1.1 )\n",
    "plt.title('Distribution of F')\n",
    "plt.legend(chart_labels, loc='best'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccc54ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Feature importance dataframe\n",
    "imp_df = pd.DataFrame({'feature': X_train.columns.values,\n",
    "                       'importance': clf.feature_importances_})\n",
    " \n",
    "# Reorder by importance\n",
    "ordered_df = imp_df.sort_values(by='importance')\n",
    "imp_range=range(1,len(imp_df.index)+1)\n",
    " \n",
    "## Barplot with confidence intervals\n",
    "height = ordered_df['importance']\n",
    "bars = ordered_df['feature']\n",
    "y_pos = np.arange(len(bars))\n",
    "\n",
    "# Create horizontal bars\n",
    "plt.barh(y_pos, height)\n",
    " \n",
    "# Create names on the y-axis\n",
    "plt.yticks(y_pos, bars)\n",
    "\n",
    "plt.xlabel(\"Mean reduction in tree impurity in random forest\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# Show graphic\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09900156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xg = XGBClassifier(objective='binary:logistic', n_estimators=200, seed=22,learning_rate=0.4,gamma = 2, reg_lambda=2,scale_pos_weight=3, max_depth=10)\n",
    "\n",
    "xg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_pred = xg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448087f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11247827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8d67dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity=cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "print(\"Specificity is: {}\".format(sensitivity))\n",
    "specificity=cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "print(\"Sensitivity is: {}\".format(specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dd2a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "y_pred_proba = xg.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"Xgb, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0,1],[0,1],'-', color='blue') #diagonal line\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447cb6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from lightgbm import LGBMClassifier\n",
    "lgb = LGBMClassifier ()\n",
    "results = {}\n",
    "start = time()\n",
    "lgb.fit(X_train,y_train)\n",
    "end = time()\n",
    "results['training_time'] = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eace3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "y_pred =lgb.predict(X_test)\n",
    "end = time()\n",
    "results['testing_time'] = end - start\n",
    "print(\"Training time: \"+\"{:.2f}\".format(results['training_time']))\n",
    "print(\"Testing time: \"+\"{:.2f}\".format(results['testing_time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8e8602",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm_lgb = confusion_matrix(y_test,y_pred)\n",
    "print(cm_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4907f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "ac_lgb = accuracy_score(y_test,y_pred)\n",
    "print(ac_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c719c12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity=cm_lgb[0][0]/(cm_lgb[0][0]+cm_lgb[0][1])\n",
    "print(\"Specificity is: {}\".format(sensitivity))\n",
    "specificity=cm_lgb[1][1]/(cm_lgb[1][0]+cm_lgb[1][1])\n",
    "print(\"Sensitivity is: {}\".format(specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c820848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "y_pred_proba = lgb.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"LGBM, auc=\"+str(auc))\n",
    "plt.legend(loc=8)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0,1],[0,1],'-', color='blue') #diagonal line\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d7531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_params = {'learning_rate':0.02, 'boosting_type':'gbdt',\n",
    "              'objective':'binary', \n",
    "              'metric':['auc', 'binary_logloss'],\n",
    "              'num_leaves':50,\n",
    "              'max_depth':10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42739916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
